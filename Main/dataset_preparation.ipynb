{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('../Datasets/Original Dataset/Dynamically Generated Hate Dataset v0.2.3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0    acl.id  X1  \\\n",
      "0           1      acl1   1   \n",
      "1           2     acl10   2   \n",
      "2           3    acl100   3   \n",
      "3           4   acl1000   4   \n",
      "4           5  acl10000   5   \n",
      "\n",
      "                                                text label      type  \\\n",
      "0                                dalits are lowlives  hate  notgiven   \n",
      "1             gay people are a burden to our society  hate  notgiven   \n",
      "2                              Arabs are not welcome  hate  notgiven   \n",
      "3  I'm not saying we should actually eliminate he...  hate  notgiven   \n",
      "4                       bananas are for black people  hate  notgiven   \n",
      "\n",
      "     target     level  split  round.base   annotator round acl.id.matched  \n",
      "0  notgiven  original  train           1  GNZuCtwed3     1            NaN  \n",
      "1  notgiven  original  train           1  GNZuCtwed3     1            NaN  \n",
      "2  notgiven  original  train           1  vDe7GN0NrL     1            NaN  \n",
      "3  notgiven  original  train           1  oemYWm1Tjg     1            NaN  \n",
      "4  notgiven  original   test           1  QiOKkCi7F8     1            NaN  \n"
     ]
    }
   ],
   "source": [
    "# print the first 5 rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         int64\n",
       "acl.id            object\n",
       "X1                 int64\n",
       "text              object\n",
       "label             object\n",
       "type              object\n",
       "target            object\n",
       "level             object\n",
       "split             object\n",
       "round.base         int64\n",
       "annotator         object\n",
       "round             object\n",
       "acl.id.matched    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the fields and their data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        41144\n",
       "acl.id            41144\n",
       "X1                41144\n",
       "text              41134\n",
       "label                 2\n",
       "type                  7\n",
       "target              409\n",
       "level                 2\n",
       "split                 3\n",
       "round.base            4\n",
       "annotator            20\n",
       "round                 7\n",
       "acl.id.matched    30098\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the number of unique values in each field\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "hate       22175\n",
       "nothate    18969\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the number of unique values and their frequency in the fields label and type\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "none              18969\n",
       "derogation         9907\n",
       "notgiven           7110\n",
       "animosity          3439\n",
       "dehumanization      906\n",
       "threatening         606\n",
       "support             207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    32924\n",
       "test      4120\n",
       "dev       4100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a column called split which is used to split the data into training and testing data\n",
    "# We will split the data into training and testing data, dev also is included in the training data since there is no option to mention dev data in the config files\n",
    "train_data = data[data['split'] != 'test']\n",
    "test_data = data[data['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the split column from the training and testing data\n",
    "train_data = train_data.drop(columns=['split'])\n",
    "test_data = test_data.drop(columns=['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training and testing data\n",
    "train_data.to_csv('../Datasets/Split Datasets/Original/train_data.csv', index=False)\n",
    "test_data.to_csv('../Datasets/Split Datasets/Original/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37024, 12)\n"
     ]
    }
   ],
   "source": [
    "# looking at the shape of the training data\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text label\n",
      "0                                 dalits are lowlives  hate\n",
      "1              gay people are a burden to our society  hate\n",
      "2                               Arabs are not welcome  hate\n",
      "3   I'm not saying we should actually eliminate he...  hate\n",
      "14  It's such a rape culture with these immigrants...  hate\n"
     ]
    }
   ],
   "source": [
    "# the only two columns we need for the classification task are text and label\n",
    "train_data = train_data[['text', 'label']]\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "hate       19907\n",
      "nothate    17117\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# printing the number of unique labels in the data\n",
    "print(train_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text label\n",
      "9914  I would love to sit down with pajeet people an...  hate\n",
      "7347  Those Muslims are vile people, they do nothing...  hate\n",
      "14    It's such a rape culture with these immigrants...  hate\n",
      "                                                   text    label\n",
      "5194  \"Chinks belong in the zoo!\"… doesn’t even make...  nothate\n",
      "9566  contrary to popular opinion, I do not want to ...  nothate\n",
      "1330  There are many Jewish people on our street but...  nothate\n"
     ]
    }
   ],
   "source": [
    "# print 3 random rows from the data for each label\n",
    "print(train_data[train_data['label'] == 'hate'].sample(3))\n",
    "print(train_data[train_data['label'] == 'nothate'].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_915139/3706388296.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['text'] = \"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate' For example dalits are lowlives -> hate, gay people are a burden to our society -> hate, That chair is vile -> nothate, Your hair is gross -> nothate, Arabs are not welcome -> hate, Obama is terrible -> nothate, Now the Text:\" + train_data['text'] + \" -> ?\"\n"
     ]
    }
   ],
   "source": [
    "# now we will append a prompt to the text data to prepare incontext finetuning dataset\n",
    "# The prompt is \"Given the text, predict whether the text is hate speech or not, You can only output one word, either \"hate\" or \"nothate\" For example \"dalits are lowlives\" -> \"hate\"\", \"gay people are a burden to our society\" -> \"hate\", \"That chair is vile\" -> \"nothate\", \"Your hair is gross\" -> \"nothate\", \"Arabs are not welcome\" -> \"hate\", \"Obama is terrible\" -> \"nothate\", Text:\"\n",
    "train_data['text'] = \"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate' For example dalits are lowlives -> hate, gay people are a burden to our society -> hate, That chair is vile -> nothate, Your hair is gross -> nothate, Arabs are not welcome -> hate, Obama is terrible -> nothate, Now the Text:\" + train_data['text'] + \" -> ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us save the dataset as a json file with commas\n",
    "train_data.to_json('../Datasets/Split Datasets/Classification/incontext/incontext_train_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0                                dalits are lowlives  hate\n",
      "1             gay people are a burden to our society  hate\n",
      "2                              Arabs are not welcome  hate\n",
      "3  I'm not saying we should actually eliminate he...  hate\n",
      "4  It's such a rape culture with these immigrants...  hate\n"
     ]
    }
   ],
   "source": [
    "# now let us create another dataset for the classification task without the examples, essentially a nocontext dataset\n",
    "# load the training data\n",
    "train_data = pd.read_csv('../Datasets/Split Datasets/Original/train_data.csv')\n",
    "\n",
    "# the only two columns we need for the classification task are text and label\n",
    "train_data = train_data[['text', 'label']]\n",
    "print(train_data.head())\n",
    "\n",
    "# Let us append the prompt to the text data which doesn't \n",
    "train_data['text'] = \"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate', the Text is:\" + train_data['text'] + \"-> ?\"\n",
    "\n",
    "# now let us save the dataset as a json file with commas\n",
    "train_data.to_json('../Datasets/Split Datasets/Classification/nocontext/nocontext_train_data.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the tokenizer to check whether the dataset is in the correct format\n",
    "\n",
    "from torchtune.models.llama3 import llama3_tokenizer\n",
    "\n",
    "tokenizer = llama3_tokenizer(\"/tmp/Llama-3.2-1B-Instruct/original/tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see if we can load the data as an instruct_dataset for the incotext dataset\n",
    "\n",
    "from torchtune.datasets import instruct_dataset\n",
    "\n",
    "from torchtune.datasets import instruct_dataset\n",
    "dataset = instruct_dataset(\n",
    "     tokenizer=tokenizer,\n",
    "     source=\"json\",\n",
    "     data_files=\"../Datasets/Split Datasets/Classification/incontext/incontext_train_data.json\",\n",
    "     column_map={\n",
    "         \"input\": \"text\",\n",
    "         \"output\": \"label\",\n",
    "     },\n",
    "     train_on_input=False,\n",
    "     packed=False,\n",
    "     split=\"train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate' For example dalits are lowlives -> hate, gay people are a burden to our society -> hate, That chair is vile -> nothate, Your hair is gross -> nothate, Arabs are not welcome -> hate, Obama is terrible -> nothate, Now the Text:dalits are lowlives -> ?hate\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = dataset[0][\"tokens\"]\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see if we can load the data as an instruct_dataset for the nocontext dataset\n",
    "\n",
    "from torchtune.datasets import instruct_dataset\n",
    "dataset = instruct_dataset(\n",
    "     tokenizer=tokenizer,\n",
    "     source=\"json\",\n",
    "     data_files=\"../Datasets/Split Datasets/Classification/nocontext/nocontext_train_data.json\",\n",
    "     column_map={\n",
    "         \"input\": \"text\",\n",
    "         \"output\": \"label\",\n",
    "     },\n",
    "     train_on_input=False,\n",
    "     packed=False,\n",
    "     split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate', the Text is:dalits are lowlives-> ?hate\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = dataset[0][\"tokens\"]\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us create the test data for the categorization task\n",
    "\n",
    "# load the testing data\n",
    "train_data = pd.read_csv('../Datasets/Split Datasets/Original/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only two columns we need for the classification task are text and label\n",
    "train_data = train_data[['text', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of people hate lazy foreigners for taking advantage of our social services, whilst sitting on their arse themselves contributing nothing - none\n",
    "# n my view, the pro terrorist immigration rhetoric is an extreme concern. - derogation\n",
    "# The concept of a nice person is the opposite to that of a woman - notgiven\n",
    "# Yeah, refugees may not always have the choice of choosing the country they want to live in but they KNOW that some countries are already struggling, why would you come here? It's selfish and you can't blame people like me who barely make minimum wage to not want them here. It's truism and you know it. - Animosity\n",
    "# BLM black monkeys are a disgrace to humanity - racists! - dehumanization\n",
    "# Boris Johnson needs to stop being this crappy and kick all the immigrants out at last - threatening\n",
    "# Murdering 6 million is not enough we would love to see more - support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us append the prompt to the test dataset\n",
    "train_data['text'] = \"Given the text, predict whether the text is hate speech or not and which category of hatespeech it falls under. Your output can only be one word, if the text is not hate speech, You output none. If you cannot decide in which category the text falls under, you can output notgiven. Otherwise you have to output one of the following categories derogation, animosity, dehumanization, threatening, support. For example, A lot of people hate lazy foreigners for taking advantage of our social services, whilst sitting on their arse themselves contributing nothing -> none, n my view, the pro terrorist immigration rhetoric is an extreme concern. -> derogation,The concept of a nice person is the opposite to that of a woman -> notgiven,Yeah, refugees may not always have the choice of choosing the country they want to live in but they KNOW that some countries are already struggling, why would you come here? It's selfish and you can't blame people like me who barely make minimum wage to not want them here. It's truism and you know it. -> Animosity,BLM black monkeys are a disgrace to humanity - racists! -> dehumanization,Boris Johnson needs to stop being this crappy and kick all the immigrants out at last -> threatening,Murdering 6 million is not enough we would love to see more -> support, Now The Text:\" + train_data['text'] + \"-> ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us save the dataset as a json file with commas\n",
    "train_data.to_json('../Datasets/Split Datasets/Categorization/incontext/incontext_train_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the testing data\n",
    "train_data = pd.read_csv('../Datasets/Split Datasets/Original/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only two columns we need for the classification task are text and label\n",
    "train_data = train_data[['text', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us append the prompt to the test dataset\n",
    "train_data['text'] = \"Given the text, predict whether the text is hate speech or not and which category of hatespeech it falls under. Your output can only be one word, if the text is not hate speech, You output none. If you cannot decide in which category the text falls under, you can output notgiven. Otherwise you have to output one of the following categories derogation, animosity, dehumanization, threatening, support. Now The Text:\" + train_data['text'] + \"-> ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us save the dataset as a json file with commas\n",
    "train_data.to_json('../Datasets/Split Datasets/Categorization/nocontext/nocontext_train_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us prepare the dataset for testing for the classification task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the testing data\n",
    "test_data = pd.read_csv('../Datasets/Split Datasets/Original/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only two columns we need for the classification task are text and label\n",
    "test_data = test_data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us append the prompt to the test dataset\n",
    "test_data['text'] = \"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate', the Text is:\" + test_data['text'] + \"-> ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test data as a csv file\n",
    "test_data.to_csv('../Datasets/Split Datasets/Classification/nocontext/nocontext_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the same process for the incontext dataset\n",
    "# load the testing data\n",
    "test_data = pd.read_csv('../Datasets/Split Datasets/Original/test_data.csv')\n",
    "\n",
    "# the only two columns we need for the classification task are text and label\n",
    "test_data = test_data[['text', 'label']]\n",
    "\n",
    "# let us append the prompt to the test dataset\n",
    "test_data['text'] = \"Given the text, predict whether the text is hate speech or not, You can only output one word, either 'hate' or 'nothate' For example dalits are lowlives -> hate, gay people are a burden to our society -> hate, That chair is vile -> nothate, Your hair is gross -> nothate, Arabs are not welcome -> hate, Obama is terrible -> nothate, Now the Text:\" + test_data['text'] + \"-> ?\"\n",
    "\n",
    "# save the test data as a csv file\n",
    "test_data.to_csv('../Datasets/Split Datasets/Classification/incontext/incontext_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us prepare the dataset for testing for the categorization task\n",
    "\n",
    "# load the testing data\n",
    "test_data = pd.read_csv('../Datasets/Split Datasets/Original/test_data.csv')\n",
    "\n",
    "# the only two columns we need for the classification task are text and type\n",
    "test_data = test_data[['text', 'type']]\n",
    "\n",
    "# let us append the prompt to the test dataset\n",
    "test_data['text'] = \"Given the text, predict whether the text is hate speech or not and which category of hatespeech it falls under. Your output can only be one word, if the text is not hate speech, You output none. If you cannot decide in which category the text falls under, you can output notgiven. Otherwise you have to output one of the following categories derogation, animosity, dehumanization, threatening, support. Now The Text:\" + test_data['text'] + \"-> ?\"\n",
    "\n",
    "# save the test data as a csv file\n",
    "test_data.to_csv('../Datasets/Split Datasets/Categorization/nocontext/nocontext_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the same process for the incontext dataset\n",
    "# load the testing data\n",
    "test_data = pd.read_csv('../Datasets/Split Datasets/Original/test_data.csv')\n",
    "\n",
    "# the only two columns we need for the classification task are text and type\n",
    "test_data = test_data[['text', 'type']]\n",
    "\n",
    "# let us append the prompt to the test dataset\n",
    "test_data['text'] = \"Given the text, predict whether the text is hate speech or not and which category of hatespeech it falls under. Your output can only be one word, if the text is not hate speech, You output none. If you cannot decide in which category the text falls under, you can output notgiven. Otherwise you have to output one of the following categories derogation, animosity, dehumanization, threatening, support. For example, A lot of people hate lazy foreigners for taking advantage of our social services, whilst sitting on their arse themselves contributing nothing -> none, n my view, the pro terrorist immigration rhetoric is an extreme concern. -> derogation,The concept of a nice person is the opposite to that of a woman -> notgiven,Yeah, refugees may not always have the choice of choosing the country they want to live in but they KNOW that some countries are already struggling, why would you come here? It's selfish and you can't blame people like me who barely make minimum wage to not want them here. It's truism and you know it. -> Animosity,BLM black monkeys are a disgrace to humanity - racists! -> dehumanization,Boris Johnson needs to stop being this crappy and kick all the immigrants out at last -> threatening,Murdering 6 million is not enough we would love to see more -> support, Now The Text:\" + test_data['text'] + \"-> ?\"\n",
    "\n",
    "# save the test data as a csv file\n",
    "test_data.to_csv('../Datasets/Split Datasets/Categorization/incontext/incontext_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the testing data\n",
    "train_data = pd.read_csv('../Datasets/Split Datasets/Original/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only two columns we need for the classification task are text and label\n",
    "train_data = train_data[['text', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with type none and notgiven\n",
    "train_data = train_data[train_data['type'] != 'none']\n",
    "train_data = train_data[train_data['type'] != 'notgiven']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us append the prompt to the test dataset\n",
    "train_data['text'] = \"Given the text, Which is hate speech,predict which kind of hate speech the text falls under. Your output can only be one word.You can Output One of the following categories derogation, animosity, dehumanization, threatening, support. For example, n my view, the pro terrorist immigration rhetoric is an extreme concern. -> derogation,Yeah, refugees may not always have the choice of choosing the country they want to live in but they KNOW that some countries are already struggling, why would you come here? It's selfish and you can't blame people like me who barely make minimum wage to not want them here. It's truism and you know it. -> Animosity,BLM black monkeys are a disgrace to humanity - racists! -> dehumanization,Boris Johnson needs to stop being this crappy and kick all the immigrants out at last -> threatening,Murdering 6 million is not enough we would love to see more -> support, Now The Text:\" + train_data['text'] + \"-> ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us save the dataset as a json file with commas\n",
    "train_data.to_json('../Datasets/MISC/Given_Hate_Categorization_train_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's prepare the test set\n",
    "\n",
    "# load the testing data\n",
    "test_data = pd.read_csv('../Datasets/Split Datasets/Original/test_data.csv')\n",
    "\n",
    "# the only two columns we need for the classification task are text and type\n",
    "test_data = test_data[['text', 'type']]\n",
    "\n",
    "# remove rows with type none and notgiven\n",
    "test_data = test_data[test_data['type'] != 'none']\n",
    "test_data = test_data[test_data['type'] != 'notgiven']\n",
    "\n",
    "# let us append the prompt to the test dataset\n",
    "test_data['text'] = \"Given the text, Which is hate speech,predict which kind of hate speech the text falls under. Your output can only be one word.You can Output One of the following categories derogation, animosity, dehumanization, threatening, support. For example, n my view, the pro terrorist immigration rhetoric is an extreme concern. -> derogation,Yeah, refugees may not always have the choice of choosing the country they want to live in but they KNOW that some countries are already struggling, why would you come here? It's selfish and you can't blame people like me who barely make minimum wage to not want them here. It's truism and you know it. -> Animosity,BLM black monkeys are a disgrace to humanity - racists! -> dehumanization,Boris Johnson needs to stop being this crappy and kick all the immigrants out at last -> threatening,Murdering 6 million is not enough we would love to see more -> support, Now The Text:\" + test_data['text'] + \"-> ?\"\n",
    "\n",
    "# save the test data as a csv file\n",
    "test_data.to_csv('../Datasets/MISC/Given_Hate_Categorization_test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
